### 목표
- 타이타닉 데이터를 활용해서 데이터 전처리, 시각화 진행
- 모델링 : 하이퍼파라미터 튜닝 (KNN, DecisionTree 모델)
- 앙상블 모델 실습


```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns # 시각화 도구
```

#### 1.데이터 로딩


```python
train = pd.read_csv('./data/train.csv')
test = pd.read_csv('./data/test.csv')
```


```python
train.shape, test.shape
```




    ((891, 12), (418, 11))




```python
target = train['Survived'] # 정답
```

#### 2. 데이터 탐색 및 전처리


```python
# 1. 결측치 확인
train.isna().sum()
```




    PassengerId      0
    Survived         0
    Pclass           0
    Name             0
    Sex              0
    Age            177
    SibSp            0
    Parch            0
    Ticket           0
    Fare             0
    Cabin          687
    Embarked         2
    dtype: int64




```python
test.isnull().sum()
```




    PassengerId      0
    Pclass           0
    Name             0
    Sex              0
    Age             86
    SibSp            0
    Parch            0
    Ticket           0
    Fare             1
    Cabin          327
    Embarked         0
    dtype: int64




```python
# 갯수가 적은 결측치는 기술통계를 활용해서 채워보자.
train['Embarked'].value_counts()

```




    S    644
    C    168
    Q     77
    Name: Embarked, dtype: int64




```python
train['Embarked'].fillna('S', inplace=True)
```


```python
test['Fare'].mean()
```




    35.6271884892086




```python
test['Fare'].fillna(test['Fare'].mean(), inplace=True)
```


```python
# 나이는 단순 기술통계보다는 상관계수를 활용해서 좀 더 정교하게 채워보자.
train.corr()['Age']
```




    PassengerId    0.036847
    Survived      -0.077221
    Pclass        -0.369226
    Age            1.000000
    SibSp         -0.308247
    Parch         -0.189119
    Fare           0.096067
    Name: Age, dtype: float64



- 상관계수를 통해 관계가 제일 깊은 Pclass 선택
- 시대적 상황을 고려해서 Sex 선택


```python
train[['Sex','Pclass','Age']].groupby(by=['Sex','Pclass']).median()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Age</th>
    </tr>
    <tr>
      <th>Sex</th>
      <th>Pclass</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">female</th>
      <th>1</th>
      <td>35.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>21.5</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">male</th>
      <th>1</th>
      <td>40.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>30.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>25.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
train_missing=train[['Sex','Pclass','Age']].groupby(by=['Sex','Pclass']).transform('median')
```


```python
train['Age'].fillna(train_missing['Age'], inplace=True)
```


```python
train.isna().sum()
```




    PassengerId      0
    Survived         0
    Pclass           0
    Name             0
    Sex              0
    Age              0
    SibSp            0
    Parch            0
    Ticket           0
    Fare             0
    Cabin          687
    Embarked         0
    dtype: int64




```python
test_missing=test[['Sex','Pclass','Age']].groupby(by=['Sex','Pclass']).transform('median')
```


```python
test['Age'].fillna(test_missing['Age'], inplace=True)
```


```python
test.isna().sum()
```




    PassengerId      0
    Pclass           0
    Name             0
    Sex              0
    Age              0
    SibSp            0
    Parch            0
    Ticket           0
    Fare             0
    Cabin          327
    Embarked         0
    dtype: int64




```python
# Cabin 결측치 채우기
# 결측치 자체를 표현하는 키워드로 처리
train['Cabin'].unique()
```




    array([nan, 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6',
           'C23 C25 C27', 'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33',
           'F G73', 'E31', 'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101',
           'F E69', 'D47', 'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4',
           'A32', 'B4', 'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35',
           'C87', 'B77', 'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19',
           'B49', 'D', 'C22 C26', 'C106', 'C65', 'E36', 'C54',
           'B57 B59 B63 B66', 'C7', 'E34', 'C32', 'B18', 'C124', 'C91', 'E40',
           'T', 'C128', 'D37', 'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44',
           'A34', 'C104', 'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14',
           'B37', 'C30', 'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38',
           'B39', 'B22', 'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68',
           'B41', 'A20', 'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48',
           'E58', 'C126', 'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63',
           'C62 C64', 'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30',
           'E121', 'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36',
           'B102', 'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42',
           'C148'], dtype=object)




```python
train['Cabin'] = train['Cabin'].str[0].fillna('M')
```


```python
test['Cabin'] = test['Cabin'].str[0].fillna('M')
```


```python
train['Cabin'].unique()
```




    array(['M', 'C', 'E', 'G', 'D', 'A', 'B', 'F', 'T'], dtype=object)




```python
train.isnull().sum().sum()
```




    0



# 시각화


```python
# countplot
sns.countplot(data=train,
             x='Pclass',
             hue='Survived')
```




    <AxesSubplot:xlabel='Pclass', ylabel='count'>




    
![output_28_1](https://user-images.githubusercontent.com/66361526/145736204-b43728d7-22e0-43da-9733-ebf81f954ec4.png)
    



```python
sns.countplot(data=train,
             x='Embarked',
             hue='Survived')
```




    <AxesSubplot:xlabel='Embarked', ylabel='count'>




    
![output_29_1](https://user-images.githubusercontent.com/66361526/145736207-40e2e641-3b44-4561-a6ee-3122776cee2d.png)
    



```python
# violinplot
```


```python
sns.violinplot(data=train,
              x='Sex',
              y='Age',
              hue='Survived',
              split = True)
```




    <AxesSubplot:xlabel='Sex', ylabel='Age'>




    
![output_31_1](https://user-images.githubusercontent.com/66361526/145736209-b4393e6e-7549-4c0b-aaad-d2266e3dd281.png)
    



```python
# kdeplot
sns.kdeplot(train['Fare'])
```




    <AxesSubplot:xlabel='Fare', ylabel='Density'>




    
![output_32_1](https://user-images.githubusercontent.com/66361526/145736211-91805c65-5b57-4426-88f1-ed98f71b9022.png)
    


#### 3. 모델링(하이퍼파라미터 튜닝)


```python
train.columns
```




    Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',
           'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],
          dtype='object')




```python
# 불필요한 컬럼 삭제(Name과 Ticket은 시간관계상 삭제)
train.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)
```


```python
test.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)
```


```python
# 원핫인코딩
one_hot = pd.get_dummies(train[['Sex','Cabin','Embarked']])
one_hot
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sex_female</th>
      <th>Sex_male</th>
      <th>Cabin_A</th>
      <th>Cabin_B</th>
      <th>Cabin_C</th>
      <th>Cabin_D</th>
      <th>Cabin_E</th>
      <th>Cabin_F</th>
      <th>Cabin_G</th>
      <th>Cabin_M</th>
      <th>Cabin_T</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>886</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>887</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>888</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>889</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>890</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>891 rows × 14 columns</p>
</div>




```python
train.drop(['Sex','Cabin','Embarked'], axis=1, inplace=True)
train = pd.concat([train,one_hot],axis=1)
```


```python
train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Sex_female</th>
      <th>Sex_male</th>
      <th>Cabin_A</th>
      <th>Cabin_B</th>
      <th>Cabin_C</th>
      <th>Cabin_D</th>
      <th>Cabin_E</th>
      <th>Cabin_F</th>
      <th>Cabin_G</th>
      <th>Cabin_M</th>
      <th>Cabin_T</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
one_hot_test = pd.get_dummies(test[['Sex','Cabin','Embarked']])
test.drop(['Sex','Cabin','Embarked'], axis=1, inplace=True)
test = pd.concat([test,one_hot_test],axis=1)
```


```python
test.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Sex_female</th>
      <th>Sex_male</th>
      <th>Cabin_A</th>
      <th>Cabin_B</th>
      <th>Cabin_C</th>
      <th>Cabin_D</th>
      <th>Cabin_E</th>
      <th>Cabin_F</th>
      <th>Cabin_G</th>
      <th>Cabin_M</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>34.5</td>
      <td>0</td>
      <td>0</td>
      <td>7.8292</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>47.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.0000</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>62.0</td>
      <td>0</td>
      <td>0</td>
      <td>9.6875</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>27.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.6625</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>22.0</td>
      <td>1</td>
      <td>1</td>
      <td>12.2875</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
# KNN, DecisionTree 모델 활용
# 모델 정의 -> 모델 학습 -> 모델 예측 -> 모델 평가
# 훈련데이터, 검증데이터, 평가데이터 분리
```


```python
x = train.drop(['Survived','Cabin_T'], axis=1)
y = target
```


```python
x.shape, y.shape
```




    ((891, 18), (891,))




```python
x_test = test
x_test.shape
```




    (418, 18)




```python
from sklearn.model_selection import train_test_split
```


```python
x_train, x_val, y_train, y_val = train_test_split(x,y,test_size=0.3,random_state=1116)
```


```python
x_train.shape, y_train.shape
```




    ((623, 18), (623,))




```python
x_val.shape, y_val.shape
```




    ((268, 18), (268,))




```python
x_test.shape
```




    (418, 18)




```python
# 모델 정의 및 하이퍼파라미터 튜닝
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score # 정확도
```


```python
# KNN
for k in range(1,100) :
    knn_model = KNeighborsClassifier(n_neighbors=k) # 모델의 복잡도를 제어
    knn_model.fit(x_train,y_train) # 훈련데이터 활용 모델학습
    pre = knn_model.predict(x_val) # 검증데이터 활용 모델예측
    score = accuracy_score(pre,y_val) # 검증데이터 예측결과 평가
    print(k,":",score)
```

    1 : 0.7350746268656716
    2 : 0.7014925373134329
    3 : 0.7126865671641791
    4 : 0.7238805970149254
    5 : 0.7126865671641791
    6 : 0.7238805970149254
    7 : 0.7089552238805971
    8 : 0.7313432835820896
    9 : 0.7388059701492538
    10 : 0.746268656716418
    11 : 0.7350746268656716
    12 : 0.753731343283582
    13 : 0.7611940298507462
    14 : 0.75
    15 : 0.7350746268656716
    16 : 0.7388059701492538
    17 : 0.746268656716418
    18 : 0.7350746268656716
    19 : 0.7276119402985075
    20 : 0.7313432835820896
    21 : 0.7164179104477612
    22 : 0.7313432835820896
    23 : 0.7164179104477612
    24 : 0.7350746268656716
    25 : 0.7238805970149254
    26 : 0.7276119402985075
    27 : 0.7126865671641791
    28 : 0.7126865671641791
    29 : 0.7126865671641791
    30 : 0.6977611940298507
    31 : 0.6977611940298507
    32 : 0.6828358208955224
    33 : 0.6865671641791045
    34 : 0.6940298507462687
    35 : 0.6940298507462687
    36 : 0.7014925373134329
    37 : 0.6828358208955224
    38 : 0.7089552238805971
    39 : 0.6791044776119403
    40 : 0.6865671641791045
    41 : 0.6828358208955224
    42 : 0.7052238805970149
    43 : 0.6902985074626866
    44 : 0.6940298507462687
    45 : 0.6716417910447762
    46 : 0.664179104477612
    47 : 0.664179104477612
    48 : 0.6791044776119403
    49 : 0.6791044776119403
    50 : 0.6791044776119403
    51 : 0.6865671641791045
    52 : 0.6828358208955224
    53 : 0.6865671641791045
    54 : 0.6791044776119403
    55 : 0.6865671641791045
    56 : 0.6940298507462687
    57 : 0.6977611940298507
    58 : 0.6940298507462687
    59 : 0.6977611940298507
    60 : 0.6977611940298507
    61 : 0.6902985074626866
    62 : 0.6865671641791045
    63 : 0.6865671641791045
    64 : 0.6940298507462687
    65 : 0.6977611940298507
    66 : 0.7014925373134329
    67 : 0.7014925373134329
    68 : 0.6940298507462687
    69 : 0.6865671641791045
    70 : 0.6977611940298507
    71 : 0.6865671641791045
    72 : 0.6902985074626866
    73 : 0.6865671641791045
    74 : 0.6902985074626866
    75 : 0.6828358208955224
    76 : 0.6865671641791045
    77 : 0.6828358208955224
    78 : 0.6791044776119403
    79 : 0.6791044776119403
    80 : 0.6753731343283582
    81 : 0.6791044776119403
    82 : 0.6828358208955224
    83 : 0.6791044776119403
    84 : 0.6791044776119403
    85 : 0.6791044776119403
    86 : 0.6828358208955224
    87 : 0.6791044776119403
    88 : 0.6828358208955224
    89 : 0.6753731343283582
    90 : 0.6753731343283582
    91 : 0.6753731343283582
    92 : 0.6716417910447762
    93 : 0.667910447761194
    94 : 0.664179104477612
    95 : 0.664179104477612
    96 : 0.667910447761194
    97 : 0.664179104477612
    98 : 0.6865671641791045
    99 : 0.6753731343283582
    


```python
from sklearn.model_selection import cross_val_score # 교차검증 함수
```


```python
# 교차검증 기법 적용
for k in range(1,100) :
    knn_model = KNeighborsClassifier(n_neighbors=k) # 모델의 복잡도를 제어
    score = cross_val_score(knn_model,x,y,cv=5)
    print(k,":",score.mean())
```

    1 : 0.6768062268533049
    2 : 0.6947774778733287
    3 : 0.718322766932396
    4 : 0.7037285794990897
    5 : 0.7003766241918272
    6 : 0.6880610131190761
    7 : 0.7004205636808737
    8 : 0.6902830958508568
    9 : 0.7060071558596448
    10 : 0.6947837549431927
    11 : 0.6992718598958007
    12 : 0.6914255225660662
    13 : 0.7060259870692361
    14 : 0.7015504362563554
    15 : 0.6992969681752557
    16 : 0.711669072876781
    17 : 0.7060385412089637
    18 : 0.7082794551503357
    19 : 0.7071621367145816
    20 : 0.7060385412089636
    21 : 0.6982110350888207
    22 : 0.7184043688406252
    23 : 0.717287050404871
    24 : 0.7217626012177516
    25 : 0.7127989454522629
    26 : 0.7127926683823991
    27 : 0.7094344360052728
    28 : 0.7015818216056745
    29 : 0.7015880986755383
    30 : 0.7015880986755383
    31 : 0.7027054171112925
    32 : 0.7038164584771829
    33 : 0.7027054171112924
    34 : 0.7004393948904651
    35 : 0.6993283535245747
    36 : 0.7004393948904651
    37 : 0.6970686083736111
    38 : 0.6948214173623752
    39 : 0.695951289937857
    40 : 0.6937103759964849
    41 : 0.6914569079153852
    42 : 0.6880861213985312
    43 : 0.6858389303872953
    44 : 0.6858514845270228
    45 : 0.6847278890214048
    46 : 0.683598016445923
    47 : 0.6824744209403051
    48 : 0.683598016445923
    49 : 0.6892159939740129
    50 : 0.6858452074571589
    51 : 0.6892097169041491
    52 : 0.6858389303872953
    53 : 0.6824744209403051
    54 : 0.6869750800326407
    55 : 0.6813633795744147
    56 : 0.6869813571025045
    57 : 0.6858640386667505
    58 : 0.6836105705856506
    59 : 0.6813571025045508
    60 : 0.6858452074571589
    61 : 0.676862720482079
    62 : 0.6779925930575608
    63 : 0.674615529470843
    64 : 0.6791036344234511
    65 : 0.676862720482079
    66 : 0.6779800389178331
    67 : 0.6701274245182349
    68 : 0.6757265708367335
    69 : 0.6723620613897432
    70 : 0.6678865105768628
    71 : 0.6667629150712447
    72 : 0.6667754692109724
    73 : 0.6634109597639821
    74 : 0.6690163831523446
    75 : 0.6667691921411085
    76 : 0.6656455966354906
    77 : 0.6667754692109723
    78 : 0.6690163831523445
    79 : 0.6723871696691984
    80 : 0.6701399786579625
    81 : 0.6746406377502981
    82 : 0.6735170422446802
    83 : 0.6757642332559162
    84 : 0.6757579561860523
    85 : 0.676894105831398
    86 : 0.6735170422446801
    87 : 0.6735233193145439
    88 : 0.6678990647165903
    89 : 0.6723934467390622
    90 : 0.6735170422446801
    91 : 0.672399723808926
    92 : 0.6690289372920721
    93 : 0.6690289372920721
    94 : 0.6679053417864541
    95 : 0.669028937292072
    96 : 0.6678990647165903
    97 : 0.6656518737053543
    98 : 0.6667691921411085
    99 : 0.6645282781997363
    


```python
final_knn_model = KNeighborsClassifier(n_neighbors=4)
final_knn_model.fit(x,y)
final_knn_pre = final_knn_model.predict(x_test)
```


```python
final_knn_pre
```




    array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,
           0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,
           1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,
           0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,
           1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
           0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
           0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,
           1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
           1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
           0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,
           0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,
           1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
           0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,
           1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,
           0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0],
          dtype=int64)




```python
submission = pd.read_csv('data/gender_submission.csv')
submission['Survived'] = final_knn_pre
submission.to_csv('mysubmission01.csv', index=False)
```


```python
# DecisionTree
# 교차검증 기법 적용
for d in range(1,50) :
    tree_model = DecisionTreeClassifier(max_depth=d) # 모델의 복잡도를 제어
    score = cross_val_score(tree_model,x,y,cv=5)
    print(d,":",score.mean())
```

    1 : 0.7867365513778168
    2 : 0.773316176009039
    3 : 0.8024606113866047
    4 : 0.805881614462369
    5 : 0.8058251208335949
    6 : 0.8080911430544221
    7 : 0.8024794425961961
    8 : 0.8058565061829139
    9 : 0.8125729709371665
    10 : 0.811436821291821
    11 : 0.8058439520431863
    12 : 0.7890276818780994
    13 : 0.7912937040989266
    14 : 0.8013809553700332
    15 : 0.7912937040989266
    16 : 0.7901638315234448
    17 : 0.7823049400539828
    18 : 0.7845395769254911
    19 : 0.782298662984119
    20 : 0.7923984683949532
    21 : 0.7901512773837174
    22 : 0.7845395769254913
    23 : 0.790157554453581
    24 : 0.786793045006591
    25 : 0.7924172996045445
    26 : 0.795775531981671
    27 : 0.7811813445483649
    28 : 0.7879103634423451
    29 : 0.7879354717218002
    30 : 0.7912937040989265
    31 : 0.7901638315234449
    32 : 0.7890465130876907
    33 : 0.7957567007720796
    34 : 0.7856631724311092
    35 : 0.7867804908668633
    36 : 0.7823049400539829
    37 : 0.7924047454648171
    38 : 0.7845458539953549
    39 : 0.7856631724311092
    40 : 0.7856568953612454
    41 : 0.7901450003138535
    42 : 0.7867993220764546
    43 : 0.7879040863724814
    44 : 0.7924172996045447
    45 : 0.7890276818780992
    46 : 0.7890214048082356
    47 : 0.7845458539953549
    48 : 0.7890276818780992
    49 : 0.7901638315234448
    


```python
final_tree_model = DecisionTreeClassifier(max_depth=8)
final_tree_model.fit(x,y)
final_tree_pre = final_tree_model.predict(x_test)
```


```python
submission['Survived'] = final_tree_pre
submission.to_csv('mysubmission02.csv', index=False)
```

#### KNN 스케일링
- KNN 데이터 스케일에 영향을 많이 받는 모델이다.
- 스케일에 영향을 받지 않는 tree모델에 비해 성능이 많이 하락되었다.


```python
from sklearn.preprocessing import RobustScaler
```


```python
r_scaler = RobustScaler()
```


```python
r_scaler.fit(x[['Fare']]) # 요금의 사분위수를 측정
```




    RobustScaler()




```python
x_copy = x.copy()
```


```python
x_copy['Fare'] = r_scaler.transform(x[['Fare']])
```


```python
x_copy['Fare']
```




    0     -0.312011
    1      2.461242
    2     -0.282777
    3      1.673732
    4     -0.277363
             ...   
    886   -0.062981
    887    0.673281
    888    0.389604
    889    0.673281
    890   -0.290356
    Name: Fare, Length: 891, dtype: float64




```python
sns.kdeplot(x_copy['Fare'])
```




    <AxesSubplot:xlabel='Fare', ylabel='Density'>




    
![output_68_1](https://user-images.githubusercontent.com/66361526/145736216-729f2e1d-967d-441c-be48-8513e0d970b0.png)
    



```python
x_test_copy = x_test.copy()
```


```python
x_test_copy['Fare'] = r_scaler.transform(x_test[['Fare']])
```


```python
final_knn_model = KNeighborsClassifier(n_neighbors=4)
final_knn_model.fit(x_copy,y)
final_knn_pre = final_knn_model.predict(x_test_copy)
```


```python
submission['Survived'] = final_knn_pre
submission.to_csv('mysubmission03.csv', index=False)
```


```python
# 전처리 파일 저장
x.to_csv('./data/preprocessing_x_train.csv', index = False)
```


```python
y.to_csv('./data/preprocessing_y_train.csv', index = False)
```


```python
x_test.to_csv('./data/preprocessing_x_test.csv', index=False)
```


```python
pd.read_csv('./data/preprocessing_x_test.csv')
```


```python

```


```python

```
